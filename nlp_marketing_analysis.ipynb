{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277987d4-9cfb-4232-9915-265f80fce8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mikail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Mikail\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47a34af-74b9-449a-9a36-b41166d5b7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"reviews.csv\", encoding=\"latin1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b96e86c-c57f-4213-a04a-086d602be1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ProductId', 'Score', 'Summary', 'Text']]\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6d37485-8357-4eba-bb4c-f7d1c41bffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(20000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944156a9-4fd1-49ed-8539-af3a8efab33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_text'] = df['Summary'] + \" \" + df['Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41821a96-c409-4b4d-8c44-354b025e531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mikail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df['clean_review'] = df['review_text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc46928a-7165-4d53-94ec-4d1ede8aa5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Mikail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = df['clean_review'].apply(lambda x: sia.polarity_scores(x)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835299d4-aa95-4a29-a6bd-434c2c16c0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.52093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0.52093</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Score  sentiment\n",
       "Score      1.00000    0.52093\n",
       "sentiment  0.52093    1.00000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Score', 'sentiment']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b83d66a1-0b4f-4744-bb9f-6914120b5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = tfidf.fit_transform(df['clean_review'])\n",
    "\n",
    "feature_names = tfidf.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba4ab94-9fdd-4f3c-afb0-8901f8a767c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'good',\n",
       " 'great',\n",
       " 'taste',\n",
       " 'one',\n",
       " 'love',\n",
       " 'product',\n",
       " 'flavor',\n",
       " 'br',\n",
       " 'would',\n",
       " 'get',\n",
       " 'best',\n",
       " 'really',\n",
       " 'dont',\n",
       " 'much',\n",
       " 'also',\n",
       " 'coffee',\n",
       " 'little',\n",
       " 'buy',\n",
       " 'time']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words = np.argsort(tfidf.idf_)[:20]\n",
    "[feature_names[i] for i in top_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1592c870-b685-4a84-b525-0a7464f90e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['taste', 'sauce', 'good', 'use', 'like', 'great', 'product', 'br']\n",
      "\n",
      "Topic 1:\n",
      "['great', 'loves', 'cat', 'love', 'treats', 'dogs', 'dog', 'food']\n",
      "\n",
      "Topic 2:\n",
      "['great', 'chocolate', 'good', 'like', 'drink', 'taste', 'flavor', 'tea']\n",
      "\n",
      "Topic 3:\n",
      "['great', 'like', 'strong', 'kcups', 'good', 'flavor', 'cup', 'coffee']\n",
      "\n",
      "Topic 4:\n",
      "['love', 'find', 'order', 'good', 'price', 'amazon', 'product', 'great']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(X_tfidf)\n",
    "\n",
    "def display_topics(model, feature_names, n_top_words=8):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {idx}:\")\n",
    "        print([feature_names[i] for i in topic.argsort()[-n_top_words:]])\n",
    "        print()\n",
    "\n",
    "display_topics(lda, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc93294-a1a8-4f48-8660-59c289243cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Marketing Insights\n",
    "\n",
    "- Topics associated with negative sentiment highlight customer pain points and areas for product or messaging improvement.\n",
    "- Positive sentiment topics reveal features and language that resonate with customers and can be emphasized in marketing and SEO content.\n",
    "- Insights can inform keyword strategy, content optimization, and customer experience improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4fea22f-11d9-4981-8f3c-7264b36eb7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    min_df=5,\n",
    "    max_df=0.9\n",
    ")\n",
    "X_tfidf = tfidf.fit_transform(df['clean_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "268ba9cb-8fc1-44af-9502-c08d26b7a66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "0    0.697909\n",
       "3    0.713487\n",
       "4    0.722097\n",
       "1    0.739784\n",
       "2    0.784496\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'] = lda.transform(X_tfidf).argmax(axis=1)\n",
    "\n",
    "df.groupby('topic')['sentiment'].mean().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe1743-5819-4673-b6ea-fa6c307bf69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topics with lower average sentiment scores indicate potential customer pain points, while higher-scoring topics highlight messaging and features that resonate positively with customers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f4fa7-0c02-48a7-a135-d9ec4e82e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic Interpretation\n",
    "\n",
    "- Topic 0 (Product taste & quality): Mixed sentiment, potential opportunity to refine messaging around flavor consistency.\n",
    "- Topic 1 (Pet food satisfaction): Strong positive sentiment, suitable for trust-building and testimonial-driven content.\n",
    "- Topic 2 (Beverages & flavor variety): Highest sentiment, highlighting features to emphasize in SEO and product descriptions.\n",
    "- Topic 3 (Coffee strength & flavor): Moderate sentiment, indicating room for expectation-setting in content.\n",
    "- Topic 4 (Price & ordering experience): Generally positive sentiment, useful for conversion-focused messaging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8130d1c-2c81-469a-aa3a-a677816e9123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
